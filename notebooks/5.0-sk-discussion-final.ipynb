{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "614eadff",
   "metadata": {},
   "source": [
    "# 5. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9f82e4",
   "metadata": {},
   "source": [
    "As we have already touched on in the results section there are points for and against using dictionaries in order to analyze the sentiment of texts. In our specific case we wanted to look into what differences can be seen between the stage of social media and the Bundestag, between different parties, and between the genders of the politicians. We came to the conclusion that we saw noticeable differences between the sentiments of the different parties with most of them being attributed to the orientation of the party itself and it's position towards the governing parties of the 19. Bundestag. Moreover, we have also seen the influence of single events and of political proposals on the sentiment expressed on Twitter and in the Bundestag. Therefore, we could see a difference in the wy sentiment was expressed in the formal context of the Bundestag and on the other hand in a more informal and personal environment on Twitter. What we could not find were noticeable differences in the genders as they seemed rather minor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef2b934",
   "metadata": {},
   "source": [
    "In regards to the methodology used in our research to determine the sentiment of the texts we went with dictionary based approaches as they worked best with our implemented pipeline, the ease of interpretation, and due to the resources given for this project. Also the fact that we had two unlabeled corpi to classify made the implementation of supervised approaches non-feasible. More complex unsupervised models like BERT implementations were to resource heavy to use again at this step as they had been already used for the topic modeling. Semi-supervised approaches could have been a very promissing approach in this regard but would have also take to many resources in the scope of our project. <br>\n",
    "Therefore, we decided to use dictionary based model in the form of Textblob and the SentiWS implementation in spacy. We compared the two approaches before deciding for TextBlob to test our hypothesis as the results seemed to be more promissing. Here one could argue that the SentiWS results could have been more realistic or maybe in reality fit the data better but as for our research the others seemed to be more insightful we took them. As for ever dicitonary approach the validity of applying the dictionary needed to be questioned as dictionaries often face problems of specific domain and are therefore sensitive to corpus given. This problem can of course also be addressed by extending the dictionary with more domain specific language and by considering moe specific filterings of the raw texts. In this aspect the influence of our preprocessing should also not be left unregarded as we have tried to make the texts more suitable for the approach. Again, there are more possibilities to be explored in this regard as we could have tried different preprocessing approaches or even left them almost completely. <br>\n",
    "As for the validity problem we implemented our own revalidation step which we used to test the results against a gold standard human coded part of the corpus. Here it needs to be noted that this should at least be done with one per cent of the corpus as suggested by literature (cite). In case of the speeches we fulfilled this requirement but for the tweets we settled for less as the corpus was to large. This could be extended and even more methods of manual coding could be inplemented in further research. One could also think about more ways to boost the reliability of the gold standard and clear systematic biases through more complex coding manual or more testing and coding run throughs. <br>\n",
    "Another problem we face are the assumptions made by the dictionary approach. As it is a bag-of-words approach we are not really considering the order of the sentences. Therefore, we can miss negations, the function of a word in a sentence is not considered and we can't account for irony in texts. Furthermore, we are getting an additivity assumption which assigns a higher sentiment score to a higher frequency of sentiment words again ignoring sentence structures. In addition through the additivity assumption we get a problem with the length of texts as it gets correlated to the sentiment of the text (cite). As we have a big differences in length due to the tweets being rather short and the speeches rather long we can't be sure that the dictionary measure is comparable for the different medias. One should definetly try to account for the variablity in length of text in future research and look further into possibilities to make the dictionary more robust to circumvent these problems. In our case, we could definitely see a lower performance for the Bundetags speeches which makes all conclusions made from them less valid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45325769",
   "metadata": {},
   "source": [
    "As with media content analysis in general but also for sentiment analysis context and perspective have a great influence on results and make an analysis hard. Considering this our approach on politicians sentiments was surely very ambitious as we are facing a long period of time analyzed and many different contexts discussed in that period. Nevertheless, we could se some noticeable patterns in the way the sentiment behaved for the politicians in relation to current topics, party affiliations, and personal views. <br>\n",
    "All in all with our analysis we were able to find some interest relations that should definitely be looked into further in future research. Moreover, there are plenty more technics that can be used in order to get better insights into sentiment of politicians from the German Bundestag. In future, one could try to find more determining factors for the sentiment of parties and individuals. What also seems to be promissing is the approach to combine sentiment analysis with the topic modelling discussed in this research report. Through that one could look deeper into the reasons how certain topics affect sentiment. <br>\n",
    "Another possible future research could be interested in the prediction of sentiment through machine learning models. This approach would be interested then in finding patterns and signs for changes in sentiment. This could than tried to used to anticipate the success of political proposals or other initiatives. Certainly the future work done on basis of this research seems promissing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
