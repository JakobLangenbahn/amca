{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eff23b2",
   "metadata": {},
   "source": [
    "### 4.2.2 Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18073fe8",
   "metadata": {},
   "source": [
    "As often stressed in literature (cite) we need to revalidate the dictionary used to see if it fits with the application we are trying to analyse. Therefore, we will use gold standard validation to see how well the dictionaries perform in comparison to human coders. We will also check if the inter coder reliability is granted with our two authors coded. <br>\n",
    "Due to the fact that context plays a major role in deciding how emotions are expressed within a text we need to be especially careful when using a non-specific dictionary to detect sentiment. Working with this limitation we addressed the issue in our validation approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b4b195",
   "metadata": {},
   "source": [
    "First, we load in the needed packages to perform the validation step. We will look at the accuracy, recall, precision and f1 score for the comparison to the gold standard of human coded sentiment. In addition we will use Cohen's Kappa to get a score for the intercoder reliability for the human coded data. These measures should proof useful in determining whether the dictionary performed well for our research questions and topic. <br>\n",
    "In addition, we also implemented a little interface to perform the gold standard validation which is why we need the ipywidgets library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17ce9a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pickle\n",
    "\n",
    "#get the scores\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import IntProgress\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5564664f",
   "metadata": {},
   "source": [
    "### Validation Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda128eb",
   "metadata": {},
   "source": [
    "Again we start of our validation with the sentiment scores for the Twitter data. First, we need to transform our dataset in a way that we can apply our gold standard validation. As until now, we got the sentiment in form of a polarity score which is given as a number between -1 and 1, we needed a way to make this scoring system manageable for human coders. (How should they distinguish between a sentiment of 0.0001 and 0.0002?) To make our lifes easier we decided to take a simple scoring system of distributing the tweets into positive, negative and neutral tweets. That way there was a less subjective classification as we can for the most part agree on what positive and negative conotated messages are. To generate the corresponding score generated by the dictionary approach we classified the sentiment as positive if the polarity was positive and negative if the polarity was negative. This only left tweets and speeches with a polarity of 0 as neutral which again needs to critically viewed as the polarity score can be biased in one direction. So we should consider the neutral assignments made by the dictionary with care. Nevertheless, for our gold standard coding we can use this scoring system. <b>\n",
    "After creating the new score values via a loop we add them as a new column to our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bda131ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up Twitter dataset for sentiment coding\n",
    "pre_data_twitter= pickle.load(open('../data/processed/tweets_processed.p','rb'))\n",
    "sentiment=[]\n",
    "for polarity in pre_data_twitter['polarity_textblob']:\n",
    "    if polarity>0:\n",
    "        sentiment.append('Positive')\n",
    "    elif polarity<0:\n",
    "        sentiment.append('Negative')\n",
    "    else:\n",
    "        sentiment.append('Neutral')\n",
    "pre_data_twitter['sentiment']=sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd46ec14",
   "metadata": {},
   "source": [
    "In preparation for the validation step we will need to define a function that let's us randomly select a certain number of tweets from our corpus. We do this by simply suffeling the data and afterwards selecting the first tweets until the desired number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c055ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to chose random tweets for manual coding\n",
    "def create_sentiment_dataset(data, number):\n",
    "    data= data.sample(frac=1)\n",
    "    data_test= data[0:number]\n",
    "    data_test.reset_index(drop=True, inplace= True)\n",
    "    return data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bca2da",
   "metadata": {},
   "source": [
    "The next step is to create the interface for the validity testing. Herefore, we also define a function that lets us display buttons we can press to select the wanted sentiment of the coder while going through the randomly selected tweets. After the coder has labeled all the given tweets we save his labels as a new column for the given dataframe and create a file were we save the coded corpus for the coder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcca91eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the test interface\n",
    "def sentiment_gold_dictionary_tweets(sentiment_df, name):\n",
    "    max_count = sentiment_df.shape[0]\n",
    "    global i\n",
    "    i = 0\n",
    "\n",
    "    button_0 = widgets.Button(description = \"Positive\")\n",
    "    button_1 = widgets.Button(description = \"Neutral\")\n",
    "    button_2 = widgets.Button(description = \"Negative\")\n",
    "    \n",
    "    chosen_elements = []\n",
    "\n",
    "    display(\"Sentiment Gold Standard\")\n",
    "\n",
    "    f = IntProgress(min=0, max=max_count)\n",
    "    display(f)\n",
    "    \n",
    "    display(sentiment_df.text_preprocessed_sentence[i])\n",
    "\n",
    "    display(button_0)\n",
    "    display(button_1)\n",
    "    display(button_2)\n",
    "\n",
    "\n",
    "    def btn_eventhandler(obj):\n",
    "        global i \n",
    "        i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        display(\"Sentiment Gold Standard\")\n",
    "        display(f)\n",
    "        f.value += 1\n",
    "                \n",
    "        choosen_text = obj.description\n",
    "        chosen_elements.append(choosen_text)\n",
    "        \n",
    "        if i < max_count:\n",
    "            \n",
    "            display(sentiment_df.text_preprocessed_sentence[i])\n",
    "            \n",
    "            display(button_0)\n",
    "            display(button_1)\n",
    "            display(button_2)\n",
    "            \n",
    "            button_0.on_click(btn_eventhandler)\n",
    "            button_1.on_click(btn_eventhandler)\n",
    "            button_2.on_click(btn_eventhandler)\n",
    "            \n",
    "        else:\n",
    "            print (\"Thanks \" + name + \" you finished all the work!\")\n",
    "            sentiment_df[\"choosen_sentiment\"] = chosen_elements\n",
    "            sentiment_df.to_csv(\"../data/processed/sentiment_gold_standard_tweets_\" + name + \".csv\", index = False)\n",
    "\n",
    "    button_0.on_click(btn_eventhandler)\n",
    "    button_1.on_click(btn_eventhandler)\n",
    "    button_2.on_click(btn_eventhandler)\n",
    "    \n",
    "    return sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f68bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "In our validation step, we use 40..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "568a1053",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=create_sentiment_dataset(pre_data_twitter, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f8929ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sentiment Gold Standard'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6981617845b49f7975753a236dccda8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=39, max=40)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks Stjepan you finished all the work!\n"
     ]
    }
   ],
   "source": [
    "#test_sentiment=sentiment_gold_dictionary_tweets(test_data,'Stjepan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59ff7f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentiment1=pd.read_csv('../data/processed/sentiment_gold_standard_tweets_Stjepan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f37dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=create_sentiment_dataset(pre_data_twitter, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1666b777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sentiment Gold Standard'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54a795e9dcb4e09bebd32f2fb76c2be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=39, max=40)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks Jakob you finished all the work!\n"
     ]
    }
   ],
   "source": [
    "#test_sentiment=sentiment_gold_dictionary_tweets(test_data,'Jakob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6848780",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentiment2=pd.read_csv('../data/processed/sentiment_gold_standard_tweets_Jakob.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20c3876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentiment_both=pd.concat([test_sentiment1,test_sentiment2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ccf6cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5494074201305393\n",
      "Accuracy Score: 0.5375\n",
      "Precision Score: 0.6026515151515152\n",
      "Recall Score: 0.5375\n"
     ]
    }
   ],
   "source": [
    "f2=f1_score(test_sentiment_both['choosen_sentiment'], test_sentiment_both['sentiment'], average='weighted')\n",
    "print('F1 Score:',f2)\n",
    "accuracy2=accuracy_score(test_sentiment_both['choosen_sentiment'], test_sentiment_both['sentiment'])\n",
    "print('Accuracy Score:',accuracy2)\n",
    "precision2=precision_score(test_sentiment_both['choosen_sentiment'], test_sentiment_both['sentiment'], average='weighted',zero_division=1)\n",
    "print('Precision Score:',precision2)\n",
    "recall2=recall_score(test_sentiment_both['choosen_sentiment'], test_sentiment_both['sentiment'], average='weighted',zero_division=1)\n",
    "print('Recall Score:',recall2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40dd86c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Positive : 0.5384615384615384\n",
      "Accuracy Score for Positive : 0.3684210526315789\n",
      "Precision Score for Positive : 1.0\n",
      "Recall Score for Positive : 0.3684210526315789\n",
      "\n",
      "F1 Score for Negative : 0.6956521739130436\n",
      "Accuracy Score for Negative : 0.5333333333333333\n",
      "Precision Score for Negative : 1.0\n",
      "Recall Score for Negative : 0.5333333333333333\n",
      "\n",
      "F1 Score for Neutral : 0.7843137254901961\n",
      "Accuracy Score for Neutral : 0.6451612903225806\n",
      "Precision Score for Neutral : 1.0\n",
      "Recall Score for Neutral : 0.6451612903225806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['Positive', 'Negative', 'Neutral']:\n",
    "    test_for_score=test_sentiment_both.loc[test_sentiment_both['choosen_sentiment']==label]\n",
    "    f2=f1_score(test_for_score['choosen_sentiment'], test_for_score['sentiment'], average='weighted')\n",
    "    accuracy2=accuracy_score(test_for_score['choosen_sentiment'], test_for_score['sentiment'])\n",
    "    precision2=precision_score(test_for_score['choosen_sentiment'], test_for_score['sentiment'], average='weighted',zero_division=1)\n",
    "    recall2=recall_score(test_for_score['choosen_sentiment'], test_for_score['sentiment'], average='weighted',zero_division=1)\n",
    "    print('F1 Score for',label,':',f2)\n",
    "    print('Accuracy Score for',label,':',accuracy2)\n",
    "    print('Precision Score for',label,':',precision2)\n",
    "    print('Recall Score for',label,':',recall2)\n",
    "    print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ee9ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=create_sentiment_dataset(pre_data_twitter, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0346e3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sentiment Gold Standard'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da7b9e4ea4c49e4a8b08660f8024e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=9, max=10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks Stjepan_inter you finished all the work!\n"
     ]
    }
   ],
   "source": [
    "#test_sentiment=sentiment_gold_dictionary_tweets(test_data,'Stjepan_inter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8f18d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sentiment Gold Standard'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1fc46c51275450eaf73e7e2331b4556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=9, max=10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks Jakob_inter you finished all the work!\n"
     ]
    }
   ],
   "source": [
    "#test_sentiment=sentiment_gold_dictionary_tweets(test_data,'Jakob_inter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5bdd599",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentiment1=pd.read_csv('../data/processed/sentiment_gold_standard_tweets_Stjepan_inter.csv')\n",
    "test_sentiment2=pd.read_csv('../data/processed/sentiment_gold_standard_tweets_Jakob_inter.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dc5febd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6825396825396826\n"
     ]
    }
   ],
   "source": [
    "#kappa\n",
    "kappa= cohen_kappa_score(test_sentiment1['choosen_sentiment'],test_sentiment2['choosen_sentiment'])\n",
    "print(kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f5f0c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validation Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6cd4927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up Speeches dataset for sentiment coding\n",
    "pre_data_speeches= pickle.load(open('../data/processed/speeches_processed.p','rb'))\n",
    "sentiment=[]\n",
    "for polarity in pre_data_speeches['polarity_textblob']:\n",
    "    if polarity>0:\n",
    "        sentiment.append('Positive')\n",
    "    elif polarity<0:\n",
    "        sentiment.append('Negative')\n",
    "    else:\n",
    "        sentiment.append('Neutral')\n",
    "pre_data_speeches['sentiment']=sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d09f88fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to chose random speeches for manual coding\n",
    "def create_sentiment_dataset(data, number):\n",
    "    data= data.sample(frac=1)\n",
    "    data_test= data[0:number]\n",
    "    data_test.reset_index(drop=True, inplace= True)\n",
    "    return data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a154f3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the test interface\n",
    "def sentiment_gold_dictionary_speeches(sentiment_df, name):\n",
    "    max_count = sentiment_df.shape[0]\n",
    "    global i\n",
    "    i = 0\n",
    "\n",
    "    button_0 = widgets.Button(description = \"Positive\")\n",
    "    button_1 = widgets.Button(description = \"Neutral\")\n",
    "    button_2 = widgets.Button(description = \"Negative\")\n",
    "    \n",
    "    chosen_elements = []\n",
    "\n",
    "    display(\"Sentiment Gold Standard\")\n",
    "\n",
    "    f = IntProgress(min=0, max=max_count)\n",
    "    display(f)\n",
    "    \n",
    "    display(sentiment_df.text_preprocessed_sentence[i])\n",
    "\n",
    "    display(button_0)\n",
    "    display(button_1)\n",
    "    display(button_2)\n",
    "\n",
    "\n",
    "    def btn_eventhandler(obj):\n",
    "        global i \n",
    "        i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        display(\"Sentiment Gold Standard\")\n",
    "        display(f)\n",
    "        f.value += 1\n",
    "                \n",
    "        choosen_text = obj.description\n",
    "        chosen_elements.append(choosen_text)\n",
    "        \n",
    "        if i < max_count:\n",
    "            \n",
    "            display(sentiment_df.text_preprocessed_sentence[i])\n",
    "            \n",
    "            display(button_0)\n",
    "            display(button_1)\n",
    "            display(button_2)\n",
    "            \n",
    "            button_0.on_click(btn_eventhandler)\n",
    "            button_1.on_click(btn_eventhandler)\n",
    "            button_2.on_click(btn_eventhandler)\n",
    "            \n",
    "        else:\n",
    "            print (\"Thanks \" + name + \" you finished all the work!\")\n",
    "            sentiment_df[\"choosen_sentiment\"] = chosen_elements\n",
    "            sentiment_df.to_csv(\"../data/processed/sentiment_gold_standard_speeches_\" + name + \".csv\", index = False)\n",
    "\n",
    "    button_0.on_click(btn_eventhandler)\n",
    "    button_1.on_click(btn_eventhandler)\n",
    "    button_2.on_click(btn_eventhandler)\n",
    "    \n",
    "    return sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df194a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=create_sentiment_dataset(pre_data_speeches, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df44383e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sentiment Gold Standard'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886b9382a03d4018bdfc7432ef0d4c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=39, max=40)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks Stjepan you finished all the work!\n"
     ]
    }
   ],
   "source": [
    "#test_sentiment=sentiment_gold_dictionary_speeches(test_data,'Stjepan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3411061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentiment1=pd.read_csv('../data/processed/sentiment_gold_standard_speeches_Stjepan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c612e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=create_sentiment_dataset(pre_data_speeches, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78531ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sentiment Gold Standard'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae35f07095e496895213437d22f7e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=39, max=40)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks Jakob you finished all the work!\n"
     ]
    }
   ],
   "source": [
    "#test_sentiment=sentiment_gold_dictionary_speeches(test_data,'Jakob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec5d5dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentiment2=pd.read_csv('../data/processed/sentiment_gold_standard_speeches_Jakob.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79ef1a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentiment_both=pd.concat([test_sentiment1,test_sentiment2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f14e1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.3975587794617645\n",
      "Accuracy Score: 0.3875\n",
      "Precision Score: 0.5754140866873065\n",
      "Recall Score: 0.3875\n"
     ]
    }
   ],
   "source": [
    "f2=f1_score(test_sentiment_both['choosen_sentiment'], test_sentiment_both['sentiment'], average='weighted')\n",
    "print('F1 Score:',f2)\n",
    "accuracy2=accuracy_score(test_sentiment_both['choosen_sentiment'], test_sentiment_both['sentiment'])\n",
    "print('Accuracy Score:',accuracy2)\n",
    "precision2=precision_score(test_sentiment_both['choosen_sentiment'], test_sentiment_both['sentiment'], average='weighted',zero_division=1)\n",
    "print('Precision Score:',precision2)\n",
    "recall2=recall_score(test_sentiment_both['choosen_sentiment'], test_sentiment_both['sentiment'], average='weighted',zero_division=1)\n",
    "print('Recall Score:',recall2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97a5d069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for  Positive : 0.8571428571428571\n",
      "Accuracy Score for  Positive : 0.75\n",
      "Precision Score for  Positive : 1.0\n",
      "Recall Score for  Positive : 0.75\n",
      "\n",
      "F1 Score for  Negative : 0.4897959183673469\n",
      "Accuracy Score for  Negative : 0.32432432432432434\n",
      "Precision Score for  Negative : 1.0\n",
      "Recall Score for  Negative : 0.32432432432432434\n",
      "\n",
      "F1 Score for  Neutral : 0.4117647058823529\n",
      "Accuracy Score for  Neutral : 0.25925925925925924\n",
      "Precision Score for  Neutral : 1.0\n",
      "Recall Score for  Neutral : 0.25925925925925924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['Positive', 'Negative', 'Neutral']:\n",
    "    test_for_score=test_sentiment_both.loc[test_sentiment_both['choosen_sentiment']==label]\n",
    "    f2=f1_score(test_for_score['choosen_sentiment'], test_for_score['sentiment'], average='weighted')\n",
    "    accuracy2=accuracy_score(test_for_score['choosen_sentiment'], test_for_score['sentiment'])\n",
    "    precision2=precision_score(test_for_score['choosen_sentiment'], test_for_score['sentiment'], average='weighted',zero_division=1)\n",
    "    recall2=recall_score(test_for_score['choosen_sentiment'], test_for_score['sentiment'], average='weighted',zero_division=1)\n",
    "    print('F1 Score for ',label,':',f2)\n",
    "    print('Accuracy Score for ',label,':',accuracy2)\n",
    "    print('Precision Score for ',label,':',precision2)\n",
    "    print('Recall Score for ',label,':',recall2)\n",
    "    print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "beb34590",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=create_sentiment_dataset(pre_data_speeches, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ae03c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sentiment Gold Standard'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec6bb758ed940a6805c0defd16bc837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=9, max=10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks Stjepan_inter you finished all the work!\n"
     ]
    }
   ],
   "source": [
    "#test_sentiment=sentiment_gold_dictionary_speeches(test_data,'Stjepan_inter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "61a06eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sentiment Gold Standard'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aae76bee64c40fb952dff4bb5fab437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=9, max=10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks Jakob_inter you finished all the work!\n"
     ]
    }
   ],
   "source": [
    "#test_sentiment=sentiment_gold_dictionary_speeches(test_data,'Jakob_inter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecb3283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentiment1=pd.read_csv('../data/processed/sentiment_gold_standard_speeches_Stjepan_inter.csv')\n",
    "test_sentiment2=pd.read_csv('../data/processed/sentiment_gold_standard_speeches_Jakob_inter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891e5c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### kappa\n",
    "kappa= cohen_kappa_score(test_sentiment1['choosen_sentiment'],test_sentiment2['choosen_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84ad6281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.509348\n"
     ]
    }
   ],
   "source": [
    "print(kappa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
