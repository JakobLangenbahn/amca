{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e378a9b3",
   "metadata": {},
   "source": [
    "### 4.1.2 Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620d82c1",
   "metadata": {},
   "source": [
    "For validating the results in the previous section, we use word and topic intrusion tests based on [Reading Tea Leaves: How Humans Interpret Topic Models](https://proceedings.neurips.cc/paper/2009/file/f92586a25bb3145facd64ab20fd554ff-Paper.pdf). We implement an interface and evaluate the results of humans label by the two authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5fb2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import IntProgress\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc63d4ad",
   "metadata": {},
   "source": [
    "#### 4.1.2.1 Word intrusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc65d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_random_document(index, number_documents):\n",
    "    rand_document = random.randrange(-1, number_documents-2)\n",
    "    if rand_document != index:\n",
    "        return rand_document \n",
    "    else:\n",
    "        return choose_random_document(index, number_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6a16326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_intrusion_dataset(topic_model):\n",
    "    number_documents = len(topic_model.get_topics())\n",
    "    records_list = []\n",
    "    for i in range(number_documents): \n",
    "        word_list = []\n",
    "        for j in range(5):\n",
    "            word_list.append(topic_model.get_topic(i-1)[j][0])\n",
    "        intruder_word = topic_model.get_topic(choose_random_document(i-1, number_documents))[0][0]\n",
    "        intruder_position = random.randrange(4)\n",
    "        word_list.insert(intruder_position, intruder_word)\n",
    "        word_list.append(intruder_word)\n",
    "        word_list.append(intruder_position)\n",
    "        records_list.append(word_list)\n",
    "    word_intrusion_df = pd.DataFrame.from_records(records_list)\n",
    "    word_intrusion_df.columns = [\"word_0\", \"word_1\", \"word_2\", \"word_3\", \"word_4\", \"word_5\", \n",
    "                                 \"intruder_word\", \"intruder_index\"]\n",
    "    return word_intrusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cd00a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_annotator_set(df, number_label, number_iaa, name_1, name_2):\n",
    "    length = df.shape[0]\n",
    "    if 2*number_label + number_iaa > length:\n",
    "        print(\"Too many labels for the size of the dataframe\")\n",
    "    df_shuffeled = df.sample(frac=1).reset_index(drop=True)\n",
    "    df_shuffeled[name_1] = [1] * (number_label+number_iaa) + [0] * (length-number_label-number_iaa)\n",
    "    df_shuffeled[name_2] = [0] * (number_label) + [1] * (number_label+number_iaa) + [0] * (length-2*number_label-number_iaa)\n",
    "    df_shuffeled[\"iaa_flag\"] = [0] * number_label + [1] * number_iaa + [0] * (length-number_label-number_iaa)\n",
    "    df_shuffeled[\"wis_label\"] = [1] * number_label + [0] * number_iaa + [1] * (length-number_label-number_iaa)\n",
    "    return df_shuffeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6d8700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_intrusion_test(word_df, name, medium):\n",
    "    intrusion_df = word_df[word_df[name] == 1].reset_index(drop = True)\n",
    "    \n",
    "    max_count = intrusion_df.shape[0]\n",
    "    global i\n",
    "    i = 0\n",
    "    \n",
    "    button_0 = widgets.Button(description = intrusion_df.word_0[i])\n",
    "    button_1 = widgets.Button(description = intrusion_df.word_1[i])\n",
    "    button_2 = widgets.Button(description = intrusion_df.word_2[i])\n",
    "    button_3 = widgets.Button(description = intrusion_df.word_3[i])\n",
    "    button_4 = widgets.Button(description = intrusion_df.word_4[i])\n",
    "    button_5 = widgets.Button(description = intrusion_df.word_5[i])\n",
    "\n",
    "\n",
    "    chosen_words = []\n",
    "    chosen_positions= []\n",
    "\n",
    "    display(\"Word Intrusion Test\")\n",
    "\n",
    "    f = IntProgress(min=0, max=max_count)\n",
    "    display(f)\n",
    "\n",
    "    display(button_0)\n",
    "    display(button_1)\n",
    "    display(button_2)\n",
    "    display(button_3)\n",
    "    display(button_4)\n",
    "    display(button_5)\n",
    "\n",
    "\n",
    "    def btn_eventhandler(position, obj):\n",
    "        global i \n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        display(\"Word Intrusion Text\")\n",
    "        display(f)\n",
    "        f.value += 1\n",
    "        \n",
    "        choosen_text = obj.description\n",
    "        chosen_words.append(choosen_text)\n",
    "        \n",
    "        chosen_positions.append(position)\n",
    "        \n",
    "        if i < max_count:\n",
    "\n",
    "            button_0 = widgets.Button(description = intrusion_df.word_0[i])\n",
    "            button_1 = widgets.Button(description = intrusion_df.word_1[i])\n",
    "            button_2 = widgets.Button(description = intrusion_df.word_2[i])\n",
    "            button_3 = widgets.Button(description = intrusion_df.word_3[i])\n",
    "            button_4 = widgets.Button(description = intrusion_df.word_4[i])\n",
    "            button_5 = widgets.Button(description = intrusion_df.word_5[i])\n",
    "            \n",
    "            display(button_0)\n",
    "            display(button_1)\n",
    "            display(button_2)\n",
    "            display(button_3)\n",
    "            display(button_4)\n",
    "            display(button_5)\n",
    "            \n",
    "            button_0.on_click(partial(btn_eventhandler,0))\n",
    "            button_1.on_click(partial(btn_eventhandler,1))\n",
    "            button_2.on_click(partial(btn_eventhandler,2))\n",
    "            button_3.on_click(partial(btn_eventhandler,3))\n",
    "            button_4.on_click(partial(btn_eventhandler,4))\n",
    "            button_5.on_click(partial(btn_eventhandler,5))\n",
    "        else:\n",
    "            print (\"Thanks \" + name + \" you finished all the work!\")\n",
    "            intrusion_df[\"chosen_word\"] = chosen_words\n",
    "            intrusion_df[\"chosen_position\"] = chosen_positions\n",
    "            intrusion_df.to_csv(\"../data/processed/word_intrusion_test_\" + name + \"_\" + medium + \".csv\", index = False)\n",
    "\n",
    "\n",
    "\n",
    "    button_0.on_click(partial(btn_eventhandler,0))\n",
    "    button_1.on_click(partial(btn_eventhandler,1))\n",
    "    button_2.on_click(partial(btn_eventhandler,2))\n",
    "    button_3.on_click(partial(btn_eventhandler,3))\n",
    "    button_4.on_click(partial(btn_eventhandler,4))\n",
    "    button_5.on_click(partial(btn_eventhandler,5))\n",
    "    \n",
    "    return intrusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a63c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_intrusion(name_1, name_2, medium):\n",
    "    df_word_intrusion_1 = pd.read_csv(\"../data/processed/word_intrusion_test_\" + name_1 + \"_\" + medium + \".csv\")\n",
    "    df_word_intrusion_2 = pd.read_csv(\"../data/processed/word_intrusion_test_\" + name_2 + \"_\" + medium + \".csv\")\n",
    "    iaa_values_1 = df_word_intrusion_1[df_word_intrusion_1.iaa_flag == 1].chosen_position.values\n",
    "    iaa_values_2 = df_word_intrusion_2[df_word_intrusion_2.iaa_flag == 1].chosen_position.values\n",
    "    kappa = cohen_kappa_score(iaa_values_1, iaa_values_2)\n",
    "    df_word_intrusion = df_word_intrusion_1.append(df_word_intrusion_2)\n",
    "    df_word = df_word_intrusion[df_word_intrusion[\"wis_label\"] == 1]\n",
    "    df_word[\"intruder_chosen\"] = df_word[\"intruder_word\"] == df_word[\"chosen_word\"]\n",
    "    return  df_word[\"intruder_chosen\"].mean(), kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cb0655",
   "metadata": {},
   "source": [
    "##### 4.1.2.1.1 Validation of tweets topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38e65b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "topic_model_tweets = BERTopic.load(\"../models/bertopic_tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a421586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate dataset\n",
    "word_intrusion_dataset_tweets = create_word_intrusion_dataset(topic_model_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8980289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_0</th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>word_4</th>\n",
       "      <th>word_5</th>\n",
       "      <th>intruder_word</th>\n",
       "      <th>intruder_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>impfstoff</td>\n",
       "      <td>afd</td>\n",
       "      <td>mal</td>\n",
       "      <td>bundestag</td>\n",
       "      <td>mensch</td>\n",
       "      <td>spd</td>\n",
       "      <td>impfstoff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tweet</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweets</td>\n",
       "      <td>pandemie</td>\n",
       "      <td>twittern</td>\n",
       "      <td>ironie</td>\n",
       "      <td>pandemie</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>digitalisierung</td>\n",
       "      <td>digital</td>\n",
       "      <td>untersuchungsausschuss</td>\n",
       "      <td>digitale</td>\n",
       "      <td>digitalpakt</td>\n",
       "      <td>infrastruktur</td>\n",
       "      <td>untersuchungsausschuss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>schön</td>\n",
       "      <td>rassismus</td>\n",
       "      <td>kaffee</td>\n",
       "      <td>trinken</td>\n",
       "      <td>tee</td>\n",
       "      <td>kommune</td>\n",
       "      <td>rassismus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arbeit</td>\n",
       "      <td>sanktion</td>\n",
       "      <td>homeoffice</td>\n",
       "      <td>kommentar</td>\n",
       "      <td>job</td>\n",
       "      <td>arbeiten</td>\n",
       "      <td>kommentar</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>hab</td>\n",
       "      <td>sorry</td>\n",
       "      <td>entschuldigung</td>\n",
       "      <td>gerne</td>\n",
       "      <td>entschuldigen</td>\n",
       "      <td>hm</td>\n",
       "      <td>gerne</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>krampfgegenrechts</td>\n",
       "      <td>aas</td>\n",
       "      <td>china</td>\n",
       "      <td>idz</td>\n",
       "      <td>troll</td>\n",
       "      <td>antifanten</td>\n",
       "      <td>china</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>meinen</td>\n",
       "      <td>rente</td>\n",
       "      <td>ingenieur</td>\n",
       "      <td>ernst</td>\n",
       "      <td>überzeugen</td>\n",
       "      <td>profi</td>\n",
       "      <td>rente</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>interview</td>\n",
       "      <td>lesen</td>\n",
       "      <td>freuen</td>\n",
       "      <td>überschrift</td>\n",
       "      <td>anhören</td>\n",
       "      <td>interviewt</td>\n",
       "      <td>freuen</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>wald</td>\n",
       "      <td>arzt</td>\n",
       "      <td>natur</td>\n",
       "      <td>artenvielfalt</td>\n",
       "      <td>ökologisch</td>\n",
       "      <td>umwelt</td>\n",
       "      <td>arzt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word_0     word_1                  word_2         word_3  \\\n",
       "0            impfstoff        afd                     mal      bundestag   \n",
       "1                tweet    twitter                  tweets       pandemie   \n",
       "2      digitalisierung    digital  untersuchungsausschuss       digitale   \n",
       "3                schön  rassismus                  kaffee        trinken   \n",
       "4               arbeit   sanktion              homeoffice      kommentar   \n",
       "..                 ...        ...                     ...            ...   \n",
       "96                 hab      sorry          entschuldigung          gerne   \n",
       "97   krampfgegenrechts        aas                   china            idz   \n",
       "98              meinen      rente               ingenieur          ernst   \n",
       "99           interview      lesen                  freuen    überschrift   \n",
       "100               wald       arzt                   natur  artenvielfalt   \n",
       "\n",
       "            word_4         word_5           intruder_word  intruder_index  \n",
       "0           mensch            spd               impfstoff               0  \n",
       "1         twittern         ironie                pandemie               3  \n",
       "2      digitalpakt  infrastruktur  untersuchungsausschuss               2  \n",
       "3              tee        kommune               rassismus               1  \n",
       "4              job       arbeiten               kommentar               3  \n",
       "..             ...            ...                     ...             ...  \n",
       "96   entschuldigen             hm                   gerne               3  \n",
       "97           troll     antifanten                   china               2  \n",
       "98      überzeugen          profi                   rente               1  \n",
       "99         anhören     interviewt                  freuen               2  \n",
       "100     ökologisch         umwelt                    arzt               1  \n",
       "\n",
       "[101 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_intrusion_dataset_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a942353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label dataset for two annotators\n",
    "word_intrusion_dataset_tweets_label = generate_annotator_set(word_intrusion_dataset_tweets, 45, 11, \"Jakob\",\n",
    "                                                             \"Stjepan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c769caac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Word Intrusion Text'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1129ab74170f4f18aa9b027c494e3aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=11, max=56)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caeda05253c14113afe2ace1166c283a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='glückwunsch', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af9e1b91f334375b7aa9d75e57026a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='herzliche', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e886ca0545d64089b0265ddeea911fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='bundesregierung', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c0eb5d904c4fd49329d1af07447282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='zusammenarbeit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9dd0b5c5a4432781f51bad486a11e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='herzlich', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d76fdb78884d2a9d71094220fee949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='lieb', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute annotation for first candidate\n",
    "df_word_intrusion_jakob_tweets = word_intrusion_test(word_intrusion_dataset_tweets_label, \"Jakob\", \"Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd727a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute annotation for second candidate\n",
    "df_word_intrusion_stjepan_tweets = word_intrusion_test(word_intrusion_dataset_tweets_label, \"Stjepan\", \"Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d12ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate intrusion score and cohens kappa\n",
    "word_intrusion_score_tweets, word_kappa_tweets = calculate_word_intrusion(\"Jakob\", \"Stjepan\", \"Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a40785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrusion score\n",
    "word_intrusion_score_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a708ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cohens kappa\n",
    "word_kappa_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9d7641",
   "metadata": {},
   "source": [
    "##### 4.1.2.1.2 Validation of speeches topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac96098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "topic_model_speeches = BERTopic.load(\"../models/bertopic_speeches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e67a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate dataset\n",
    "word_intrusion_dataset_speeches = create_word_intrusion_dataset(topic_model_speeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a85193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label dataset for two annotators\n",
    "word_intrusion_dataset_speeches_label = generate_annotator_set(word_intrusion_dataset_speeches, 1, 1, \"Jakob\",\n",
    "                                                             \"Stjepan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0189bb40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Execute annotation for first candidate\n",
    "df_word_intrusion_jakob_speeches = word_intrusion_test(word_intrusion_dataset_speeches_label, \"Jakob\", \"Speeches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff54591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute annotation for second candidate\n",
    "df_word_intrusion_stjepan_speeches = word_intrusion_test(word_intrusion_dataset_speeches_label, \"Stjepan\",\n",
    "                                                         \"Speeches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867a8dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate intrusion score and cohens kappa\n",
    "word_intrusion_score_speeches, word_kappa_speeches = calculate_word_intrusion(\"Jakob\", \"Stjepan\", \"Speeches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168fc43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrusion score\n",
    "word_intrusion_score_speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7796f575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cohens kappa\n",
    "word_kappa_speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7921326c",
   "metadata": {},
   "source": [
    "#### 4.1.2.2 Topic Intrusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe225a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_topic_string(topic_info):\n",
    "    word_list = []\n",
    "    for i in range(8):\n",
    "        word_list.append(topic_info[i][0])\n",
    "    return \", \".join(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_topic_intrusion_dataset(data, topic_model, topic_probabilities, test_number = 100):\n",
    "    number_documents = data.shape[0]\n",
    "    if number_documents < test_number:\n",
    "        print(\"You can only choose as many test as number of documents!\")\n",
    "    number_topics = len(topic_model.get_topics())\n",
    "    records_list = []\n",
    "    for i in range(test_number): \n",
    "        topic_list = []\n",
    "        high_probability_documents = sorted(zip(topic_probabilities[i].tolist(), list(range(number_topics))), reverse=True)[:3]\n",
    "        low_probability_documents = sorted(zip(topic_probabilities[i].tolist(), list(range(number_topics))), reverse=True)[3:]\n",
    "        for j in range(3):\n",
    "            topic_index = high_probability_documents[j][1]\n",
    "            topic_list.append(create_topic_string(topic_model.get_topic(topic_index)))\n",
    "        intruder_document = low_probability_documents[random.randrange(number_topics-4)]\n",
    "        intruder_topic = create_topic_string(topic_model.get_topic(intruder_document[1]))\n",
    "        intruder_position = random.randrange(4)\n",
    "        topic_list.insert(intruder_position, intruder_topic)\n",
    "        for k in range(3):\n",
    "            topic_index = high_probability_documents[k][1]\n",
    "            topic_list.append(high_probability_documents[k][0])\n",
    "        topic_list.insert(intruder_position + 4, intruder_document[0])\n",
    "        topic_list.append(intruder_topic)\n",
    "        topic_list.append(intruder_document[0])\n",
    "        topic_list.append(intruder_position)\n",
    "        topic_list.append(data[\"text\"][i])\n",
    "        records_list.append(topic_list)\n",
    "    df = pd.DataFrame.from_records(records_list)\n",
    "    df.columns = [\"topic_0\", \"topic_1\", \"topic_2\", \"topic_3\",\"probability_topic_0\",\"probability_topic_1\",\n",
    "                  \"probability_topic_2\",\"probability_topic_3\", \"intruder_topic\", \"intruder_topic_probability\",\n",
    "                  \"intruder_index\", \"text\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a7e085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_intrusion_test(intrusion_df, name, medium):\n",
    "    intrusion_df = intrusion_df[intrusion_df[name] == 1].reset_index(drop = True)\n",
    "    \n",
    "    max_count = intrusion_df.shape[0]\n",
    "    global i\n",
    "    i = 0\n",
    "\n",
    "    button_0 = widgets.Button(description = intrusion_df.topic_0[i])\n",
    "    button_1 = widgets.Button(description = intrusion_df.topic_1[i])\n",
    "    button_2 = widgets.Button(description = intrusion_df.topic_2[i])\n",
    "    button_3 = widgets.Button(description = intrusion_df.topic_3[i])\n",
    "    \n",
    "    chosen_elements = []\n",
    "    chosen_positions = []\n",
    "    chosen_probabilities = []\n",
    "\n",
    "    display(\"Topic Intrusion Test\")\n",
    "\n",
    "    f = IntProgress(min=0, max=max_count)\n",
    "    display(f)\n",
    "    \n",
    "    display(intrusion_df.text[i][0:1000])\n",
    "\n",
    "    display(button_0)\n",
    "    display(button_1)\n",
    "    display(button_2)\n",
    "    display(button_3)\n",
    "\n",
    "\n",
    "    def btn_eventhandler(position, column, obj):\n",
    "        \n",
    "        global i\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        display(\"Topic Intrusion Text\")\n",
    "        display(f)\n",
    "        f.value += 1\n",
    "                \n",
    "        choosen_text = obj.description\n",
    "        chosen_elements.append(choosen_text)\n",
    "        chosen_positions.append(position)\n",
    "        chosen_probabilities.append(intrusion_df[column][i])\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        if i < max_count:\n",
    "\n",
    "            button_0 = widgets.Button(description = intrusion_df.topic_0[i])\n",
    "            button_1 = widgets.Button(description = intrusion_df.topic_1[i])\n",
    "            button_2 = widgets.Button(description = intrusion_df.topic_2[i])\n",
    "            button_3 = widgets.Button(description = intrusion_df.topic_3[i])\n",
    "            \n",
    "            display(intrusion_df.text[i][0:1000])\n",
    "            \n",
    "            display(button_0)\n",
    "            display(button_1)\n",
    "            display(button_2)\n",
    "            display(button_3)\n",
    "            \n",
    "            button_0.on_click(partial(btn_eventhandler,0,\"probability_topic_0\"))\n",
    "            button_1.on_click(partial(btn_eventhandler,1,\"probability_topic_1\"))\n",
    "            button_2.on_click(partial(btn_eventhandler,2,\"probability_topic_2\"))\n",
    "            button_3.on_click(partial(btn_eventhandler,3,\"probability_topic_3\"))\n",
    "        else:\n",
    "            print (\"Thanks \" + name + \" you finished all the work!\")\n",
    "            intrusion_df[\"chosen_topic\"] = chosen_elements\n",
    "            intrusion_df[\"chosen_position\"] = chosen_positions\n",
    "            intrusion_df[\"chosen_topic_probability\"] = chosen_probabilities\n",
    "            intrusion_df.to_csv(\"../data/processed/topic_intrusion_test_\" + name + \"_\" + medium + \".csv\", index = False)\n",
    "\n",
    "\n",
    "\n",
    "    button_0.on_click(partial(btn_eventhandler,0,\"probability_topic_0\"))\n",
    "    button_1.on_click(partial(btn_eventhandler,1,\"probability_topic_1\"))\n",
    "    button_2.on_click(partial(btn_eventhandler,2,\"probability_topic_2\"))\n",
    "    button_3.on_click(partial(btn_eventhandler,3,\"probability_topic_3\"))\n",
    "    \n",
    "    return intrusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef76d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_topic_intrusion(name_1, name_2, medium):\n",
    "    df_topic_intrusion_1 = pd.read_csv(\"../data/processed/topic_intrusion_test_\" + name_1 + \"_\" + medium + \".csv\")\n",
    "    df_topic_intrusion_2 = pd.read_csv(\"../data/processed/topic_intrusion_test_\" + name_2 + \"_\" + medium + \".csv\")\n",
    "    iaa_values_1 = df_topic_intrusion_1[df_topic_intrusion_1.iaa_flag == 1].chosen_position.values\n",
    "    iaa_values_2 = df_topic_intrusion_2[df_topic_intrusion_2.iaa_flag == 1].chosen_position.values\n",
    "    kappa = cohen_kappa_score(iaa_values_1, iaa_values_2)\n",
    "    df_topic_intrusion = df_topic_intrusion_1.append(df_topic_intrusion_2)\n",
    "    df_topic = df_topic_intrusion[df_topic_intrusion[\"wis_label\"] == 1]\n",
    "    df_topic[\"intruder_score\"] = np.log(df_topic[\"intruder_topic_probability\"]) - np.log(df_topic[\"chosen_topic_probability\"])\n",
    "    return  df_topic[\"intruder_score\"].mean(), kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3522140e",
   "metadata": {},
   "source": [
    "##### 4.1.2.2.1 Validation of tweets topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d708a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('../data/processed/probabilities_tweets_bert.pickle', 'rb') as handle:\n",
    "    topic_probabilities_tweets = pickle.load(handle)\n",
    "with open( \"../data/processed/tweets_processed.p\", \"rb\" ) as handle:\n",
    "    tweets_processed = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de8acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "topic_model_tweets = BERTopic.load(\"../models/bertopic_tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate dataset\n",
    "topic_intrusion_dataset_tweets = create_topic_intrusion_dataset(tweets_processed, topic_model_tweets,\n",
    "                                                               topic_probabilities_tweets, test_number = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf04d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label dataset for two annotators\n",
    "topic_intrusion_dataset_tweets_label = generate_annotator_set(topic_intrusion_dataset_tweets, 1, 1, \"Jakob\",\n",
    "                                                             \"Stjepan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0163c42b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Execute annotation for first candidate\n",
    "df_topic_intrusion_jakob_tweets = topic_intrusion_test(topic_intrusion_dataset_tweets_label, \"Jakob\", \"Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de620f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute annotation for second candidate\n",
    "df_topic_intrusion_stjepan_tweets = topic_intrusion_test(topic_intrusion_dataset_tweets_label, \"Stjepan\", \"Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50205f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate intrusion score and cohens kappa\n",
    "topic_intrusion_score_tweets, topic_kappa_tweets = calculate_topic_intrusion(\"Jakob\", \"Stjepan\", \"Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbfdd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrusion score\n",
    "topic_intrusion_score_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced65763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cohens kappa\n",
    "topic_kappa_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b40e1cf",
   "metadata": {},
   "source": [
    "##### 4.1.2.2.2 Validation of speeches topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73da8f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('../data/processed/probabilities_speeches_bert.pickle', 'rb') as handle:\n",
    "    topic_probabilities_speeches = pickle.load(handle)\n",
    "with open( \"../data/processed/speeches_processed.p\", \"rb\" ) as handle:\n",
    "    speeches_processed = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0440ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "topic_model_speeches = BERTopic.load(\"../models/bertopic_speeches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da139ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate dataset\n",
    "topic_intrusion_dataset_speeches = create_topic_intrusion_dataset(speeches_processed, topic_model_speeches,\n",
    "                                                               topic_probabilities_speeches, test_number = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c3f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label dataset for two annotators\n",
    "topic_intrusion_dataset_speeches_label = generate_annotator_set(topic_intrusion_dataset_speeches, 1, 1, \"Jakob\",\n",
    "                                                             \"Stjepan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3326ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Execute annotation for first candidate\n",
    "df_topic_intrusion_jakob_speeches = topic_intrusion_test(topic_intrusion_dataset_speeches_label, \"Jakob\", \"Speeches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaa843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute annotation for second candidate\n",
    "df_topic_intrusion_stjepan_speeches = topic_intrusion_test(topic_intrusion_dataset_speeches_label, \"Stjepan\", \"Speeches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ad0af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate intrusion score and cohens kappa\n",
    "topic_intrusion_score_speeches, topic_kappa_speeches = calculate_topic_intrusion(\"Jakob\", \"Stjepan\", \"Speeches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9322437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrusion score\n",
    "topic_intrusion_score_speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8703504",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cohens kappa\n",
    "topic_kappa_speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b59f5e",
   "metadata": {},
   "source": [
    "Based on the results of the validation we can infer that the model is."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
