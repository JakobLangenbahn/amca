{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e378a9b3",
   "metadata": {},
   "source": [
    "### 4.1.2 Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620d82c1",
   "metadata": {},
   "source": [
    "For validating the results in the previous section, we use word and topic intrusion tests based on [Reading Tea Leaves: How Humans Interpret Topic Models](https://proceedings.neurips.cc/paper/2009/file/f92586a25bb3145facd64ab20fd554ff-Paper.pdf). We implement an interface and evaluate the results of humans label by the two authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import IntProgress\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc63d4ad",
   "metadata": {},
   "source": [
    "#### 4.1.2.1 Word intrusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd187209",
   "metadata": {},
   "source": [
    "Word intrusion measures the coherence of topics. For this we show annotators 5 high probability keywords of a particular topic and an intruder keyword form another topic and give them the task to identify the intruder keyword. The model precision as measured by the word intrusion score is then defined as the the number of time the intruder keyword was chosen divided by the number of topics shown. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70d6b7b",
   "metadata": {},
   "source": [
    "##### 4.1.2.1.1 Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd4eb58",
   "metadata": {},
   "source": [
    "Before we can execute the word intrusion task we need to define a set of help functions. We are creating an simple interface for this task to be executed in the Notebooks cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc65d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a random document searcher\n",
    "def choose_random_document(index, number_documents):\n",
    "    rand_document = random.randrange(-1, number_documents-2)\n",
    "    if rand_document != index:\n",
    "        return rand_document \n",
    "    else:\n",
    "        return choose_random_document(index, number_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a16326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating a word intrusion dataset\n",
    "def create_word_intrusion_dataset(topic_model):\n",
    "    number_documents = len(topic_model.get_topics())\n",
    "    records_list = []\n",
    "    for i in range(number_documents): \n",
    "        word_list = []\n",
    "        for j in range(5):\n",
    "            word_list.append(topic_model.get_topic(i-1)[j][0])\n",
    "        intruder_word = topic_model.get_topic(choose_random_document(i-1, number_documents))[0][0]\n",
    "        intruder_position = random.randrange(4)\n",
    "        word_list.insert(intruder_position, intruder_word)\n",
    "        word_list.append(intruder_word)\n",
    "        word_list.append(intruder_position)\n",
    "        records_list.append(word_list)\n",
    "    word_intrusion_df = pd.DataFrame.from_records(records_list)\n",
    "    word_intrusion_df.columns = [\"word_0\", \"word_1\", \"word_2\", \"word_3\", \"word_4\", \"word_5\", \n",
    "                                 \"intruder_word\", \"intruder_index\"]\n",
    "    return word_intrusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd00a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that divides the word intrusion dataset into seperate sets for the the annotators\n",
    "def generate_annotator_set(df, number_label, number_iaa, name_1, name_2):\n",
    "    length = df.shape[0]\n",
    "    if 2*number_label + number_iaa > length:\n",
    "        print(\"Too many labels for the size of the dataframe\")\n",
    "    df_shuffeled = df.sample(frac=1).reset_index(drop=True)\n",
    "    df_shuffeled[name_1] = [1] * (number_label+number_iaa) + [0] * (length-number_label-number_iaa)\n",
    "    df_shuffeled[name_2] = [0] * (number_label) + [1] * (number_label+number_iaa) + [0] * (length-2*number_label-number_iaa)\n",
    "    df_shuffeled[\"iaa_flag\"] = [0] * number_label + [1] * number_iaa + [0] * (length-number_label-number_iaa)\n",
    "    df_shuffeled[\"wis_label\"] = [1] * number_label + [0] * number_iaa + [1] * (length-number_label-number_iaa)\n",
    "    return df_shuffeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d8700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that offers an interface in Jupyter notebook for the word intrusion task\n",
    "def word_intrusion_test(word_df, name, medium):\n",
    "    intrusion_df = word_df[word_df[name] == 1].reset_index(drop = True)\n",
    "    \n",
    "    max_count = intrusion_df.shape[0]\n",
    "    global i\n",
    "    i = 0\n",
    "    \n",
    "    button_0 = widgets.Button(description = intrusion_df.word_0[i])\n",
    "    button_1 = widgets.Button(description = intrusion_df.word_1[i])\n",
    "    button_2 = widgets.Button(description = intrusion_df.word_2[i])\n",
    "    button_3 = widgets.Button(description = intrusion_df.word_3[i])\n",
    "    button_4 = widgets.Button(description = intrusion_df.word_4[i])\n",
    "    button_5 = widgets.Button(description = intrusion_df.word_5[i])\n",
    "\n",
    "\n",
    "    chosen_words = []\n",
    "    chosen_positions= []\n",
    "\n",
    "    display(\"Word Intrusion Test\")\n",
    "\n",
    "    f = IntProgress(min=0, max=max_count)\n",
    "    display(f)\n",
    "\n",
    "    display(button_0)\n",
    "    display(button_1)\n",
    "    display(button_2)\n",
    "    display(button_3)\n",
    "    display(button_4)\n",
    "    display(button_5)\n",
    "\n",
    "\n",
    "    def btn_eventhandler(position, obj):\n",
    "        global i \n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        display(\"Word Intrusion Text\")\n",
    "        display(f)\n",
    "        f.value += 1\n",
    "        \n",
    "        choosen_text = obj.description\n",
    "        chosen_words.append(choosen_text)\n",
    "        \n",
    "        chosen_positions.append(position)\n",
    "        \n",
    "        if i < max_count:\n",
    "\n",
    "            button_0 = widgets.Button(description = intrusion_df.word_0[i])\n",
    "            button_1 = widgets.Button(description = intrusion_df.word_1[i])\n",
    "            button_2 = widgets.Button(description = intrusion_df.word_2[i])\n",
    "            button_3 = widgets.Button(description = intrusion_df.word_3[i])\n",
    "            button_4 = widgets.Button(description = intrusion_df.word_4[i])\n",
    "            button_5 = widgets.Button(description = intrusion_df.word_5[i])\n",
    "            \n",
    "            display(button_0)\n",
    "            display(button_1)\n",
    "            display(button_2)\n",
    "            display(button_3)\n",
    "            display(button_4)\n",
    "            display(button_5)\n",
    "            \n",
    "            button_0.on_click(partial(btn_eventhandler,0))\n",
    "            button_1.on_click(partial(btn_eventhandler,1))\n",
    "            button_2.on_click(partial(btn_eventhandler,2))\n",
    "            button_3.on_click(partial(btn_eventhandler,3))\n",
    "            button_4.on_click(partial(btn_eventhandler,4))\n",
    "            button_5.on_click(partial(btn_eventhandler,5))\n",
    "        else:\n",
    "            print (\"Thanks \" + name + \" you finished all the work!\")\n",
    "            intrusion_df[\"chosen_word\"] = chosen_words\n",
    "            intrusion_df[\"chosen_position\"] = chosen_positions\n",
    "            intrusion_df.to_csv(\"../data/processed/word_intrusion_test_\" + name + \"_\" + medium + \".csv\", index = False)\n",
    "\n",
    "\n",
    "\n",
    "    button_0.on_click(partial(btn_eventhandler,0))\n",
    "    button_1.on_click(partial(btn_eventhandler,1))\n",
    "    button_2.on_click(partial(btn_eventhandler,2))\n",
    "    button_3.on_click(partial(btn_eventhandler,3))\n",
    "    button_4.on_click(partial(btn_eventhandler,4))\n",
    "    button_5.on_click(partial(btn_eventhandler,5))\n",
    "    \n",
    "    return intrusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a63c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the word intrusion score for the two annotator sets\n",
    "def calculate_word_intrusion(name_1, name_2, medium):\n",
    "    df_word_intrusion_1 = pd.read_csv(\"../data/processed/word_intrusion_test_\" + name_1 + \"_\" + medium + \".csv\")\n",
    "    df_word_intrusion_2 = pd.read_csv(\"../data/processed/word_intrusion_test_\" + name_2 + \"_\" + medium + \".csv\")\n",
    "    iaa_values_1 = df_word_intrusion_1[df_word_intrusion_1.iaa_flag == 1].chosen_position.values\n",
    "    iaa_values_2 = df_word_intrusion_2[df_word_intrusion_2.iaa_flag == 1].chosen_position.values\n",
    "    kappa = cohen_kappa_score(iaa_values_1, iaa_values_2)\n",
    "    df_word_intrusion = df_word_intrusion_1.append(df_word_intrusion_2)\n",
    "    df_word = df_word_intrusion[df_word_intrusion[\"wis_label\"] == 1]\n",
    "    df_word[\"intruder_chosen\"] = df_word[\"intruder_word\"] == df_word[\"chosen_word\"]\n",
    "    return  df_word[\"intruder_chosen\"].mean(), kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cb0655",
   "metadata": {},
   "source": [
    "##### 4.1.2.1.2 Validation of tweets topic model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9583e915",
   "metadata": {},
   "source": [
    "Based on the above defined functions, we are going to execute the word intrusion task for the tweets BERTopic model. The annotation is done by the two authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e65b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "topic_model_tweets = BERTopic.load(\"../models/bertopic_tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a421586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate dataset\n",
    "word_intrusion_dataset_tweets = create_word_intrusion_dataset(topic_model_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label dataset for two annotators\n",
    "word_intrusion_dataset_tweets_label = generate_annotator_set(word_intrusion_dataset_tweets, 45, 11, \"Jakob\",\n",
    "                                                             \"Stjepan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c769caac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Execute annotation for first candidate\n",
    "# Uncomment if annotation is repeated\n",
    "# df_word_intrusion_jakob_tweets = word_intrusion_test(word_intrusion_dataset_tweets_label, \"Jakob\", \"Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd727a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute annotation for second candidate\n",
    "# Uncomment if annotation is repeated\n",
    "# df_word_intrusion_stjepan_tweets = word_intrusion_test(word_intrusion_dataset_tweets_label, \"Stjepan\", \"Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d12ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate intrusion score and cohens kappa\n",
    "word_intrusion_score_tweets, word_kappa_tweets = calculate_word_intrusion(\"Jakob\", \"Stjepan\", \"Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a708ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cohens kappa\n",
    "print(\"Cohens kappa is: \" + str(round(word_kappa_tweets,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf42315",
   "metadata": {},
   "source": [
    "Our inter annotator agreement is on a satisfactory level and shows a good consensus of our annotations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a40785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrusion score\n",
    "print(\"The word intrusion score is: \" + str(round(word_intrusion_score_tweets,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648d73f7",
   "metadata": {},
   "source": [
    "We see an a good intrusion score as many of the intruder words were detected. These results could be improved by fixing the identified limitations of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9d7641",
   "metadata": {},
   "source": [
    "##### 4.1.2.1.2 Validation of speeches topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac96098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "topic_model_speeches = BERTopic.load(\"../models/bertopic_speeches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e67a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate dataset\n",
    "word_intrusion_dataset_speeches = create_word_intrusion_dataset(topic_model_speeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a85193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label dataset for two annotators\n",
    "word_intrusion_dataset_speeches_label = generate_annotator_set(word_intrusion_dataset_speeches, 10, 5, \"Jakob\",\n",
    "                                                             \"Stjepan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0189bb40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Execute annotation for first candidate\n",
    "# df_word_intrusion_jakob_speeches = word_intrusion_test(word_intrusion_dataset_speeches_label, \"Jakob\", \"Speeches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff54591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute annotation for second candidate\n",
    "# df_word_intrusion_stjepan_speeches = word_intrusion_test(word_intrusion_dataset_speeches_label, \"Stjepan\", \"Speeches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867a8dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate intrusion score and cohens kappa\n",
    "word_intrusion_score_speeches, word_kappa_speeches = calculate_word_intrusion(\"Jakob\", \"Stjepan\", \"Speeches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7796f575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cohens kappa\n",
    "print(\"Cohens kappa is: \" + str(round(word_kappa_speeches,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5de23b8",
   "metadata": {},
   "source": [
    "Our inter annotator agreement is on a satisfactory level and shows a good consensus of our annotations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168fc43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrusion score\n",
    "print(\"The word intrusion score is: \" + str(round(word_intrusion_score_speeches,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0c52b1",
   "metadata": {},
   "source": [
    "We see an a good intrusion score as many of the intruder words were detected. These results could be improved by fixing the identified limitations of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7921326c",
   "metadata": {},
   "source": [
    "#### 4.1.2.2 Topic Intrusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74a0ef9",
   "metadata": {},
   "source": [
    "By measurng the topic intrusion score we want to test if the algorithms probability distribution of topics for the documents seems to match the human assesment. For this we show an excerpt of the document, the three topics with the highest probability for this topic and a random low probability topic. To calculate the topic intrusion score we take the mean of the differences of the log probabilities of the selected topic and the true topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe225a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that combines key words into a single string\n",
    "def create_topic_string(topic_info):\n",
    "    word_list = []\n",
    "    for i in range(8):\n",
    "        word_list.append(topic_info[i][0])\n",
    "    return \", \".join(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that prepares the topic intrusion dataset\n",
    "def create_topic_intrusion_dataset(data, topic_model, topic_probabilities, test_number = 100):\n",
    "    number_documents = data.shape[0]\n",
    "    if number_documents < test_number:\n",
    "        print(\"You can only choose as many test as number of documents!\")\n",
    "    number_topics = len(topic_model.get_topics())\n",
    "    records_list = []\n",
    "    for i in range(test_number): \n",
    "        topic_list = []\n",
    "        high_probability_documents = sorted(zip(topic_probabilities[i].tolist(), list(range(number_topics))), reverse=True)[:3]\n",
    "        low_probability_documents = sorted(zip(topic_probabilities[i].tolist(), list(range(number_topics))), reverse=True)[3:]\n",
    "        for j in range(3):\n",
    "            topic_index = high_probability_documents[j][1]\n",
    "            topic_list.append(create_topic_string(topic_model.get_topic(topic_index)))\n",
    "        intruder_document = low_probability_documents[random.randrange(number_topics-4)]\n",
    "        intruder_topic = create_topic_string(topic_model.get_topic(intruder_document[1]))\n",
    "        intruder_position = random.randrange(4)\n",
    "        topic_list.insert(intruder_position, intruder_topic)\n",
    "        for k in range(3):\n",
    "            topic_index = high_probability_documents[k][1]\n",
    "            topic_list.append(high_probability_documents[k][0])\n",
    "        topic_list.insert(intruder_position + 4, intruder_document[0])\n",
    "        topic_list.append(intruder_topic)\n",
    "        topic_list.append(intruder_document[0])\n",
    "        topic_list.append(intruder_position)\n",
    "        topic_list.append(data[\"text\"][i])\n",
    "        records_list.append(topic_list)\n",
    "    df = pd.DataFrame.from_records(records_list)\n",
    "    df.columns = [\"topic_0\", \"topic_1\", \"topic_2\", \"topic_3\",\"probability_topic_0\",\"probability_topic_1\",\n",
    "                  \"probability_topic_2\",\"probability_topic_3\", \"intruder_topic\", \"intruder_topic_probability\",\n",
    "                  \"intruder_index\", \"text\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a7e085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that generate the interface for the topic intrusion test\n",
    "def topic_intrusion_test(intrusion_df, name, medium):\n",
    "    intrusion_df = intrusion_df[intrusion_df[name] == 1].reset_index(drop = True)\n",
    "    \n",
    "    max_count = intrusion_df.shape[0]\n",
    "    global i\n",
    "    i = 0\n",
    "    \n",
    "    layout = widgets.Layout(width='auto')\n",
    "\n",
    "    button_0 = widgets.Button(description = intrusion_df.topic_0[i], layout = layout)\n",
    "    button_1 = widgets.Button(description = intrusion_df.topic_1[i], layout = layout)\n",
    "    button_2 = widgets.Button(description = intrusion_df.topic_2[i], layout = layout)\n",
    "    button_3 = widgets.Button(description = intrusion_df.topic_3[i], layout = layout)\n",
    "    \n",
    "    chosen_elements = []\n",
    "    chosen_positions = []\n",
    "    chosen_probabilities = []\n",
    "\n",
    "    display(\"Topic Intrusion Test\")\n",
    "\n",
    "    f = IntProgress(min=0, max=max_count)\n",
    "    display(f)\n",
    "    \n",
    "    if len(intrusion_df.text[i]) < 1100:\n",
    "        display(intrusion_df.text[i][0:1100])\n",
    "    else :\n",
    "        display(intrusion_df.text[i][100:1100])\n",
    "\n",
    "    display(button_0)\n",
    "    display(button_1)\n",
    "    display(button_2)\n",
    "    display(button_3)\n",
    "\n",
    "\n",
    "    def btn_eventhandler(position, column, obj):\n",
    "        \n",
    "        global i\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        display(\"Topic Intrusion Text\")\n",
    "        display(f)\n",
    "        f.value += 1\n",
    "                \n",
    "        choosen_text = obj.description\n",
    "        chosen_elements.append(choosen_text)\n",
    "        chosen_positions.append(position)\n",
    "        chosen_probabilities.append(intrusion_df[column][i])\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        if i < max_count:\n",
    "\n",
    "            button_0 = widgets.Button(description = intrusion_df.topic_0[i], layout = layout)\n",
    "            button_1 = widgets.Button(description = intrusion_df.topic_1[i], layout = layout)\n",
    "            button_2 = widgets.Button(description = intrusion_df.topic_2[i], layout = layout)\n",
    "            button_3 = widgets.Button(description = intrusion_df.topic_3[i], layout = layout)\n",
    "            \n",
    "            if len(intrusion_df.text[i]) < 1100:\n",
    "                display(intrusion_df.text[i][0:1000])\n",
    "            else :\n",
    "                display(intrusion_df.text[i][100:1100])\n",
    "            \n",
    "            display(button_0)\n",
    "            display(button_1)\n",
    "            display(button_2)\n",
    "            display(button_3)\n",
    "            \n",
    "            button_0.on_click(partial(btn_eventhandler,0,\"probability_topic_0\"))\n",
    "            button_1.on_click(partial(btn_eventhandler,1,\"probability_topic_1\"))\n",
    "            button_2.on_click(partial(btn_eventhandler,2,\"probability_topic_2\"))\n",
    "            button_3.on_click(partial(btn_eventhandler,3,\"probability_topic_3\"))\n",
    "        else:\n",
    "            print (\"Thanks \" + name + \" you finished all the work!\")\n",
    "            intrusion_df[\"chosen_topic\"] = chosen_elements\n",
    "            intrusion_df[\"chosen_position\"] = chosen_positions\n",
    "            intrusion_df[\"chosen_topic_probability\"] = chosen_probabilities\n",
    "            intrusion_df.to_csv(\"../data/processed/topic_intrusion_test_\" + name + \"_\" + medium + \".csv\", index = False)\n",
    "\n",
    "\n",
    "\n",
    "    button_0.on_click(partial(btn_eventhandler,0,\"probability_topic_0\"))\n",
    "    button_1.on_click(partial(btn_eventhandler,1,\"probability_topic_1\"))\n",
    "    button_2.on_click(partial(btn_eventhandler,2,\"probability_topic_2\"))\n",
    "    button_3.on_click(partial(btn_eventhandler,3,\"probability_topic_3\"))\n",
    "    \n",
    "    return intrusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef76d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calulate the topic intrusion score\n",
    "def calculate_topic_intrusion(name_1, name_2, medium):\n",
    "    df_topic_intrusion_1 = pd.read_csv(\"../data/processed/topic_intrusion_test_\" + name_1 + \"_\" + medium + \".csv\")\n",
    "    df_topic_intrusion_2 = pd.read_csv(\"../data/processed/topic_intrusion_test_\" + name_2 + \"_\" + medium + \".csv\")\n",
    "    iaa_values_1 = df_topic_intrusion_1[df_topic_intrusion_1.iaa_flag == 1].chosen_position.values\n",
    "    iaa_values_2 = df_topic_intrusion_2[df_topic_intrusion_2.iaa_flag == 1].chosen_position.values\n",
    "    kappa = cohen_kappa_score(iaa_values_1, iaa_values_2)\n",
    "    df_topic_intrusion = df_topic_intrusion_1.append(df_topic_intrusion_2)\n",
    "    df_topic = df_topic_intrusion[df_topic_intrusion[\"wis_label\"] == 1]\n",
    "    df_topic[\"intruder_score\"] = np.log(df_topic[\"intruder_topic_probability\"]) - np.log(df_topic[\"chosen_topic_probability\"])\n",
    "    return  df_topic[\"intruder_score\"].mean(), kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3522140e",
   "metadata": {},
   "source": [
    "##### 4.1.2.2.1 Validation of tweets topic model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fd5a50",
   "metadata": {},
   "source": [
    "In the first step we calculate the validation score for the tweets BERTopic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d708a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open( \"../data/processed/tweets_processed_bert.pickle\", \"rb\" ) as handle:\n",
    "    tweets_processed_bert = pickle.load(handle)\n",
    "with open('../data/processed/probabilities_tweets_bert.pickle', 'rb') as handle:\n",
    "    topic_probabilities_tweets = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de8acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# topic_model_tweets = BERTopic.load(\"../models/bertopic_tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate dataset\n",
    "topic_intrusion_dataset_tweets = create_topic_intrusion_dataset(tweets_processed_bert, topic_model_tweets,\n",
    "                                                               topic_probabilities_tweets, test_number = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf04d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label dataset for two annotators\n",
    "topic_intrusion_dataset_tweets_label = generate_annotator_set(topic_intrusion_dataset_tweets, 40, 10, \"Jakob\",\n",
    "                                                             \"Stjepan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0163c42b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Execute annotation for first candidate\n",
    "# df_topic_intrusion_jakob_tweets = topic_intrusion_test(topic_intrusion_dataset_tweets_label, \"Jakob\", \"Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de620f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute annotation for second candidate\n",
    "# df_topic_intrusion_stjepan_tweets = topic_intrusion_test(topic_intrusion_dataset_tweets_label, \"Stjepan\", \"Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50205f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate intrusion score and cohens kappa\n",
    "topic_intrusion_score_tweets, topic_kappa_tweets = calculate_topic_intrusion(\"Jakob\", \"Stjepan\", \"Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced65763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cohens kappa\n",
    "print(\"Cohens kappa is: \" + str(round(topic_kappa_tweets,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd93a61",
   "metadata": {},
   "source": [
    "Our inter annotator agreement is on a satisfactory level and shows a good consensus of our annotations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbfdd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrusion score\n",
    "print(\"The topic intrusion score is: \" + str(round(topic_intrusion_score_tweets,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37088cc5",
   "metadata": {},
   "source": [
    "It is difficult to objectively evaluate the resulting topic intrusion score. But comparing with the results from the article, we can infer that this score is at least satisfactory and validates our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b40e1cf",
   "metadata": {},
   "source": [
    "##### 4.1.2.2.2 Validation of speeches topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73da8f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open( \"../data/processed/speeches_processed_bert.pickle\", \"rb\" ) as handle:\n",
    "    speeches_processed_bert = pickle.load(handle).reset_index(drop = True)\n",
    "with open('../data/processed/probabilities_speeches_bert.pickle', 'rb') as handle:\n",
    "    topic_probabilities_speeches = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0440ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# topic_model_speeches = BERTopic.load(\"../models/bertopic_speeches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da139ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate dataset\n",
    "topic_intrusion_dataset_speeches = create_topic_intrusion_dataset(speeches_processed_bert, topic_model_speeches,\n",
    "                                                               topic_probabilities_speeches, test_number = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2227fa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label dataset for two annotators\n",
    "topic_intrusion_dataset_speeches_label = generate_annotator_set(topic_intrusion_dataset_speeches, 40, 10, \"Jakob\",\n",
    "                                                             \"Stjepan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3326ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Execute annotation for first candidate\n",
    "# df_topic_intrusion_jakob_speeches = topic_intrusion_test(topic_intrusion_dataset_speeches_label, \"Jakob\", \"Speeches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaa843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute annotation for second candidate\n",
    "# df_topic_intrusion_stjepan_speeches = topic_intrusion_test(topic_intrusion_dataset_speeches_label, \"Stjepan\", \"Speeches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de41e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate intrusion score and cohens kappa\n",
    "topic_intrusion_score_speeches, topic_kappa_speeches = calculate_topic_intrusion(\"Jakob\", \"Stjepan\", \"Speeches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8703504",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cohens kappa\n",
    "print(\"Cohens kappa is: \" + str(round(topic_kappa_speeches,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151ee30",
   "metadata": {},
   "source": [
    "The inter annotator agreement on this task is rather small. We did expect this as it was quite difficult to infer the topics from an excerpt from the speeches, as they are generally quite long and therefore it is not easy to infer the right topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9322437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrusion score\n",
    "print(\"The word intrusion score is: \" + str(round(topic_intrusion_score_speeches,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cf4e1d",
   "metadata": {},
   "source": [
    "It is difficult to objectively evaluate the resulting topic intrusion score. But comparing with the results from the article, we can infer that this score is at least satisfactory and validates our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4222f577",
   "metadata": {},
   "source": [
    "#### 4.1.2.3 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6db035",
   "metadata": {},
   "source": [
    "Based on the topic and word intrusion measures we evaluated in these section, we can infer an satisfactory validity of our models. There are different possibility of improvement and we detected several limtation in the results section, however the model still offers noticeable interesting insights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
