{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Twitter_Name</th>\n",
       "      <th>Reply_Count</th>\n",
       "      <th>Retweet_Count</th>\n",
       "      <th>Like_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-12-24 09:06:37+00:00</td>\n",
       "      <td>1474305500472922113</td>\n",
       "      <td>Ich w√ºnsche Ihnen ein frohes und gesegnetes We...</td>\n",
       "      <td>rbrinkhaus</td>\n",
       "      <td>Ralph Brinkhaus</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-17 13:41:57+00:00</td>\n",
       "      <td>1471838074413924356</td>\n",
       "      <td>Herzlichen Gl√ºckwunsch @_FriedrichMerz. Alles ...</td>\n",
       "      <td>rbrinkhaus</td>\n",
       "      <td>Ralph Brinkhaus</td>\n",
       "      <td>133.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-15 12:34:54+00:00</td>\n",
       "      <td>1471096426381942791</td>\n",
       "      <td>@dieLinke Die Rede in voller L√§nge gibt es in ...</td>\n",
       "      <td>rbrinkhaus</td>\n",
       "      <td>Ralph Brinkhaus</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-12-15 11:58:36+00:00</td>\n",
       "      <td>1471087291913449472</td>\n",
       "      <td>Eine Demokratie braucht eine starke #Oppositio...</td>\n",
       "      <td>rbrinkhaus</td>\n",
       "      <td>Ralph Brinkhaus</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-12-15 11:58:35+00:00</td>\n",
       "      <td>1471087286301380616</td>\n",
       "      <td>Eine gef√§hrliche Mischung sehen wir in der #Mi...</td>\n",
       "      <td>rbrinkhaus</td>\n",
       "      <td>Ralph Brinkhaus</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                   Datetime             Tweet Id  \\\n",
       "0          0  2021-12-24 09:06:37+00:00  1474305500472922113   \n",
       "1          1  2021-12-17 13:41:57+00:00  1471838074413924356   \n",
       "2          2  2021-12-15 12:34:54+00:00  1471096426381942791   \n",
       "3          3  2021-12-15 11:58:36+00:00  1471087291913449472   \n",
       "4          4  2021-12-15 11:58:35+00:00  1471087286301380616   \n",
       "\n",
       "                                                Text    Username  \\\n",
       "0  Ich w√ºnsche Ihnen ein frohes und gesegnetes We...  rbrinkhaus   \n",
       "1  Herzlichen Gl√ºckwunsch @_FriedrichMerz. Alles ...  rbrinkhaus   \n",
       "2  @dieLinke Die Rede in voller L√§nge gibt es in ...  rbrinkhaus   \n",
       "3  Eine Demokratie braucht eine starke #Oppositio...  rbrinkhaus   \n",
       "4  Eine gef√§hrliche Mischung sehen wir in der #Mi...  rbrinkhaus   \n",
       "\n",
       "      Twitter_Name  Reply_Count  Retweet_Count  Like_Count  \n",
       "0  Ralph Brinkhaus         24.0            5.0        82.0  \n",
       "1  Ralph Brinkhaus        133.0           22.0       611.0  \n",
       "2  Ralph Brinkhaus          7.0            2.0        13.0  \n",
       "3  Ralph Brinkhaus          8.0            1.0        33.0  \n",
       "4  Ralph Brinkhaus          7.0            1.0        24.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob_de import TextBlobDE as TextBlob\n",
    "import numpy as np\n",
    "\n",
    "#read in Twitter data\n",
    "tweets_raw = pd.read_csv('/Users/stjepankusenic/PycharmProjects/amca/data/raw/Bundestag_Tweets.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "\n",
    "# Create emoji matcher\n",
    "import re\n",
    "emoji = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.remove_stopwords(doc)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create spacy pipeline\n",
    "pipeline_exclude = ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'ner', 'morphologizer']\n",
    "nlp_twitter = spacy.load('de_core_news_sm', exclude=pipeline_exclude)\n",
    "nlp_twitter.Defaults.stop_words |= {\"\\n    \"}\n",
    "\n",
    "@Language.component(\"Lemmatize text\")\n",
    "def lemmatize_text(doc):\n",
    "    doc = [token.lemma_ for token in doc]\n",
    "    doc = ' '.join(doc)\n",
    "    return nlp_twitter.make_doc(doc)\n",
    "\n",
    "@Language.component(\"Lowercase Text\")\n",
    "def lowercase(doc):\n",
    "    doc = [token.lower_ for token in doc]\n",
    "    doc = ' '.join(doc)\n",
    "    return nlp_twitter.make_doc(doc)\n",
    "\n",
    "@Language.component(\"Remove URLs\")\n",
    "def remove_urls(doc):\n",
    "    doc = [token.text for token in doc if not token.like_url]\n",
    "    doc = ' '.join(doc)\n",
    "    return nlp_twitter.make_doc(doc)\n",
    "\n",
    "@Language.component(\"Remove emojis\")\n",
    "def remove_emojis(doc):\n",
    "    doc = [token.text for token in doc if not re.match(emoji, token.text)]\n",
    "    doc = ' '.join(doc)\n",
    "    return nlp_twitter.make_doc(doc)\n",
    "\n",
    "@Language.component(\"Remove mentions\")\n",
    "def remove_mentions(doc):\n",
    "    doc = [token.text for token in doc if not re.match(\"@.*\", token.text)]\n",
    "    doc = ' '.join(doc)\n",
    "    return nlp_twitter.make_doc(doc)\n",
    "\n",
    "@Language.component(\"Remove stopwords and punctuation\")\n",
    "def remove_stopwords(doc):\n",
    "    doc = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return doc\n",
    "\n",
    "# The add_pipe function appends our functions to the default pipeline.\n",
    "#nlp_twitter.add_pipe(\"emoji\", first=True)\n",
    "nlp_twitter.add_pipe(\"Lemmatize text\", name=\"Lemmatize text\", last=True)\n",
    "nlp_twitter.add_pipe(\"Lowercase Text\", name=\"Lowercase Text\", last=True)\n",
    "nlp_twitter.add_pipe(\"Remove URLs\", name=\"Remove URLs\", last=True)\n",
    "nlp_twitter.add_pipe(\"Remove emojis\", name=\"Remove emojis\", last=True)\n",
    "nlp_twitter.add_pipe(\"Remove mentions\", name=\"Remove mentions\", last=True)\n",
    "nlp_twitter.add_pipe(\"Remove stopwords and punctuation\", name=\"Remove stopwords and punctuation\", last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through all the politicians we want to analyze\n",
    "data=[]\n",
    "for name in ['Ralph Brinkhaus','Hermann Gr√∂he', 'Nadine Sch√∂n' ,'Norbert R√∂ttgen' , 'Peter Altmaier' , 'Jens Spahn' , 'Matthias Hauer',\n",
    "            'Christian Lindner' , 'Marco Buschmann' , 'Bettina Stark-Watzinger', 'Alexander Lambsdorff' , 'Johannes Vogel' , 'Konstantin Kuhle' , 'Marie-Agnes Strack-Zimmermann',\n",
    "            'Lars Klingbeil üá™üá∫' , 'Saskia Esken' , 'Hubertus Heil' , 'Heiko Maas üá™üá∫' , 'Martin Schulz' , 'Dr. Karamba Diaby' , 'Prof. Karl Lauterbach',\n",
    "            'SteffiLemke' , 'Cem √ñzdemir' , 'Katrin G√∂ring-Eckardt' , 'Konstantin v. Notz' , 'Britta Ha√üelmann' , 'Sven Lehmann' , 'Annalena Baerbock (Archiv)',\n",
    "            'Sahra Wagenknecht' , 'Bernd Riexinger' , 'Niema Movassat' , 'Jan Korte' , 'Dietmar Bartsch' , 'Gregor Gysi' , 'Sevim Daƒüdelen, MdB',\n",
    "            'Alice Weidel' , 'Beatrix von Storch' , 'Joana Cotar' , 'üá©üá™ Stephan Brandner üá©üá™' , 'Tino Chrupalla' , 'G√∂tz Fr√∂mming, MdB' , 'Leif-Erik Holm']:\n",
    "    #get tweets from the specific politician and from the desired period\n",
    "    tweets_analyzing =tweets_raw.loc[tweets_raw['Twitter_Name']==name]\n",
    "    tweets_analyzing1 =tweets_analyzing.loc[tweets_analyzing['Datetime']>='2017-10-24']\n",
    "    tweets_analyzing2 =tweets_analyzing1.loc[tweets_analyzing1['Datetime']<='2021-10-26']\n",
    "    #preprocess the tweets\n",
    "    tweets =tweets_analyzing2.Text\n",
    "    test_tweets = tweets.progress_apply(nlp_twitter)\n",
    "    #create sentiment scores\n",
    "    preprocess=[]\n",
    "    for item in test_tweets:\n",
    "        preprocess.append(' '.join([word for word in item]))\n",
    "\n",
    "    preprocessed=pd.DataFrame(preprocess)\n",
    "\n",
    "    blobs=preprocessed[0].apply(TextBlob)\n",
    "    sentiment=[]\n",
    "    for blob in blobs:\n",
    "        sentiment.append(blob.sentiment)\n",
    "    #get the scores\n",
    "    polarity=[]\n",
    "    subjectivity=[]\n",
    "    for egg in sentiment:\n",
    "        polarity.append(egg.polarity)\n",
    "        subjectivity.append(egg.subjectivity)\n",
    "    #get the means and medians of both values \n",
    "    p_mean = np.mean(polarity)\n",
    "    s_mean = np.mean(subjectivity)\n",
    "\n",
    "    #get the number of positive, neutral and negative tweets\n",
    "    positive_p=0\n",
    "    neutral_p=0\n",
    "    negative_p=0\n",
    "    for item_p in polarity:\n",
    "        if item_p>0:\n",
    "            positive_p += 1\n",
    "        elif item_p<0:\n",
    "            negative_p += 1\n",
    "        else:\n",
    "            neutral_p += 1\n",
    "    #set up list to secure the values generated\n",
    "    data.append([tweets_analyzing2['Twitter_Name'].iloc[0],p_mean,s_mean,positive_p,neutral_p,negative_p])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up dataframe with all values\n",
    "dataf = pd.DataFrame(data, columns=['Name','Polarity_mean','Subjectivity_mean','Num_pos_tweets','Num_neutral_tweets','Num_neg_tweets'])\n",
    "display(dataf)\n",
    "dataf.to_csv('sentiment_scores_01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the mean for Polarity and sum over number of tweets from the six parties represented\n",
    "CDU_polarity = np.mean(dataf['Polarity_mean'][0:7])\n",
    "print('CDU Sentiment: ',CDU_polarity)\n",
    "FDP_polarity = np.mean(dataf['Polarity_mean'][7:14])\n",
    "print('FDP Sentiment: ',FDP_polarity)\n",
    "SPD_polarity = np.mean(dataf['Polarity_mean'][14:21])\n",
    "print('SPD Sentiment: ',SPD_polarity)\n",
    "GRUENE_polarity = np.mean(dataf['Polarity_mean'][21:28])\n",
    "print('GRUENE Sentiment: ',GRUENE_polarity)\n",
    "LINKE_polarity = np.mean(dataf['Polarity_mean'][28:35])\n",
    "print('LINKE Sentiment: ',LINKE_polarity)\n",
    "AFD_polarity = np.mean(dataf['Polarity_mean'][35:42])\n",
    "print('AFD Sentiment: ',AFD_polarity)\n",
    "print( )\n",
    "\n",
    "for category in ['Num_pos_tweets','Num_neutral_tweets','Num_neg_tweets']:\n",
    "    CDU_cat = np.sum(dataf[category][0:7])\n",
    "    print('CDU ',category,': ',CDU_cat)\n",
    "    FDP_cat = np.sum(dataf[category][7:14])\n",
    "    print('FDP ',category,': ',FDP_cat)\n",
    "    SPD_cat = np.sum(dataf[category][14:21])\n",
    "    print('SPD ',category,': ',SPD_cat)\n",
    "    GRUENE_cat = np.sum(dataf[category][21:28])\n",
    "    print('GRUENE ',category,': ',GRUENE_cat)\n",
    "    LINKE_cat = np.sum(dataf[category][28:35])\n",
    "    print('LINKE ',category,': ',LINKE_cat)\n",
    "    AFD_cat = np.sum(dataf[category][35:42])\n",
    "    print('AFD ',category,': ',AFD_cat)\n",
    "    print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the mean for Polarity and sum over number of tweets for male and female politicians\n",
    "female_polarity= np.mean(dataf.loc[dataf['Name'].isin(['Nadine Sch√∂n' ,'Bettina Stark-Watzinger','Marie-Agnes Strack-Zimmermann','Saskia Esken' ,'SteffiLemke' ,'Katrin G√∂ring-Eckardt' ,'Britta Ha√üelmann' ,'Annalena Baerbock (Archiv)','Sahra Wagenknecht' ,'Sevim Daƒüdelen, MdB','Alice Weidel' ,'Beatrix von Storch'])]['Polarity_mean'])\n",
    "print('Female Sentiment:',female_polarity)\n",
    "for category in ['Num_pos_tweets','Num_neutral_tweets','Num_neg_tweets']:\n",
    "    female_cat = np.sum(dataf.loc[dataf['Name'].isin(['Nadine Sch√∂n' ,'Bettina Stark-Watzinger','Marie-Agnes Strack-Zimmermann','Saskia Esken' ,'SteffiLemke' ,'Katrin G√∂ring-Eckardt' ,'Britta Ha√üelmann' ,'Annalena Baerbock (Archiv)','Sahra Wagenknecht' ,'Sevim Daƒüdelen, MdB','Alice Weidel' ,'Beatrix von Storch'])][category])\n",
    "    print('Female ',category,': ',female_cat)\n",
    "\n",
    "male_polarity= np.mean(dataf.loc[~dataf['Name'].isin(['Nadine Sch√∂n' ,'Bettina Stark-Watzinger','Marie-Agnes Strack-Zimmermann','Saskia Esken' ,'SteffiLemke' ,'Katrin G√∂ring-Eckardt' ,'Britta Ha√üelmann' ,'Annalena Baerbock (Archiv)','Sahra Wagenknecht' ,'Sevim Daƒüdelen, MdB','Alice Weidel' ,'Beatrix von Storch'])]['Polarity_mean'])\n",
    "print('Male Sentiment:',male_polarity)\n",
    "for category in ['Num_pos_tweets','Num_neutral_tweets','Num_neg_tweets']:\n",
    "    male_cat = np.sum(dataf.loc[~dataf['Name'].isin(['Nadine Sch√∂n' ,'Bettina Stark-Watzinger','Marie-Agnes Strack-Zimmermann','Saskia Esken' ,'SteffiLemke' ,'Katrin G√∂ring-Eckardt' ,'Britta Ha√üelmann' ,'Annalena Baerbock (Archiv)','Sahra Wagenknecht' ,'Sevim Daƒüdelen, MdB','Alice Weidel' ,'Beatrix von Storch'])][category])\n",
    "    print('Male ',category,': ',male_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the polarity of tweets over time\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i=1\n",
    "for name in ['Ralph Brinkhaus','Hermann Gr√∂he', 'Nadine Sch√∂n' ,'Norbert R√∂ttgen' , 'Peter Altmaier' , 'Jens Spahn' , 'Matthias Hauer',\n",
    "            'Christian Lindner' , 'Marco Buschmann' , 'Bettina Stark-Watzinger', 'Alexander Lambsdorff' , 'Johannes Vogel' , 'Konstantin Kuhle' , 'Marie-Agnes Strack-Zimmermann',\n",
    "            'Lars Klingbeil üá™üá∫' , 'Saskia Esken' , 'Hubertus Heil' , 'Heiko Maas üá™üá∫' , 'Martin Schulz' , 'Dr. Karamba Diaby' , 'Prof. Karl Lauterbach',\n",
    "            'SteffiLemke' , 'Cem √ñzdemir' , 'Katrin G√∂ring-Eckardt' , 'Konstantin v. Notz' , 'Britta Ha√üelmann' , 'Sven Lehmann' , 'Annalena Baerbock (Archiv)',\n",
    "            'Sahra Wagenknecht' , 'Bernd Riexinger' , 'Niema Movassat' , 'Jan Korte' , 'Dietmar Bartsch' , 'Gregor Gysi' , 'Sevim Daƒüdelen, MdB',\n",
    "            'Alice Weidel' , 'Beatrix von Storch' , 'Joana Cotar' , 'üá©üá™ Stephan Brandner üá©üá™' , 'Tino Chrupalla' , 'G√∂tz Fr√∂mming, MdB' , 'Leif-Erik Holm']:\n",
    "    #get tweets from the specific politician and from the desired period\n",
    "    tweets_analyzing =tweets_raw.loc[tweets_raw['Twitter_Name']==name]\n",
    "    tweets_analyzing1 =tweets_analyzing.loc[tweets_analyzing['Datetime']>='2017-10-24']\n",
    "    tweets_analyzing2 =tweets_analyzing1.loc[tweets_analyzing1['Datetime']<='2021-10-26']\n",
    "    #preprocess the tweets\n",
    "    tweets =tweets_analyzing2.Text\n",
    "    test_tweets = tweets.progress_apply(nlp_twitter)\n",
    "    #create sentiment scores\n",
    "    preprocess=[]\n",
    "    for item in test_tweets:\n",
    "        preprocess.append(' '.join([word for word in item]))\n",
    "\n",
    "    preprocessed=pd.DataFrame(preprocess)\n",
    "\n",
    "    blobs=preprocessed[0].apply(TextBlob)\n",
    "    sentiment=[]\n",
    "    for blob in blobs:\n",
    "        sentiment.append(blob.sentiment)\n",
    "    #get the scores\n",
    "    polarity=[]\n",
    "    for egg in sentiment:\n",
    "        polarity.append(egg.polarity)\n",
    "    #get the desired dates and convert timestamp\n",
    "    tweets_analyzing2['polarity']=polarity\n",
    "    tweets_analyzing2['Datetime']=pd.to_datetime(tweets_analyzing2['Datetime'])\n",
    "\n",
    "    dates=tweets_analyzing2['Datetime']\n",
    "    values=tweets_analyzing2['polarity']\n",
    "\n",
    "    #smooth the curve, higher sigma means more smoothing\n",
    "    if len(polarity)>18999:\n",
    "        s=100\n",
    "    elif len(polarity)>17999:\n",
    "        s=95\n",
    "    elif len(polarity)>16999:\n",
    "        s=90\n",
    "    elif len(polarity)>15999:\n",
    "        s=85\n",
    "    elif len(polarity)>14999:\n",
    "        s=80\n",
    "    elif len(polarity)>13999:\n",
    "        s=75\n",
    "    elif len(polarity)>12999:\n",
    "        s=70\n",
    "    elif len(polarity)>11999:\n",
    "        s=65\n",
    "    elif len(polarity)>10999:\n",
    "        s=60\n",
    "    elif len(polarity)>9999:\n",
    "        s=55\n",
    "    elif len(polarity)>8999:\n",
    "        s=50\n",
    "    elif len(polarity)>7999:\n",
    "        s=45\n",
    "    elif len(polarity)>6999:\n",
    "        s=40\n",
    "    elif len(polarity)>5999:\n",
    "        s=35\n",
    "    elif len(polarity)>4999:\n",
    "        s=30\n",
    "    elif len(polarity)>3999:\n",
    "        s=25\n",
    "    elif len(polarity)>2999:\n",
    "        s=20\n",
    "    elif len(polarity)>1999:\n",
    "        s=15\n",
    "    elif len(polarity)>1399:\n",
    "        s=10\n",
    "    else:\n",
    "        s=8\n",
    "    ysmoothed = gaussian_filter1d(values, sigma=s)\n",
    "\n",
    "    fig = plt.figure(figsize=(20,200))\n",
    "    ax = fig.add_subplot(42,1,i)\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d.%m.%y'))    \n",
    "    fig.autofmt_xdate(rotation=45)\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Polarity Score')\n",
    "    plt.plot(dates, ysmoothed)\n",
    "    plt.show()\n",
    "    i +=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}